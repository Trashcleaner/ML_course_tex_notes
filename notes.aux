\relax 
\bibstyle{apalike-cs}
\@writefile{toc}{\contentsline {title}{Machine Learning A-Z}{1}}
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{{}}{1}}
\@writefile{toc}{\contentsline {section}{Introduction}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Preprocessing}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Problems with datasets}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Code template in Python}{3}}
\@writefile{lol}{\contentsline {lstlisting}{code/datapreprocessingtemplate.py}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Code template in R}{3}}
\@writefile{lol}{\contentsline {lstlisting}{code/datapreprocessingtemplate.R}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Regression}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Regression code template in Python}{5}}
\@writefile{lol}{\contentsline {lstlisting}{code/regression\textunderscore template.py}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Regression code template in R}{5}}
\@writefile{lol}{\contentsline {lstlisting}{code/regression\textunderscore template.R}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Simple Linear Regression}{6}}
\@writefile{lol}{\contentsline {lstlisting}{code/simple\textunderscore linear\textunderscore regression.py}{7}}
\@writefile{lol}{\contentsline {lstlisting}{code/simple\textunderscore linear\textunderscore regression.R}{8}}
\newlabel{uloha1:pic1}{{2.3}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Simple Linear regression in Python}}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Multiple Linear Regression}{8}}
\@writefile{toc}{\contentsline {subsubsection}{Assumptions of Linear Regression}{8}}
\@writefile{toc}{\contentsline {subsubsection}{5 methods of building models}{9}}
\@writefile{toc}{\contentsline {subsubsection}{Backward elimination}{9}}
\@writefile{toc}{\contentsline {subsubsection}{Forward Selection}{9}}
\@writefile{toc}{\contentsline {subsubsection}{Bidirectional elimination}{10}}
\@writefile{toc}{\contentsline {subsubsection}{Code}{10}}
\@writefile{lol}{\contentsline {lstlisting}{code/multiple\textunderscore linear\textunderscore regression.py}{10}}
\@writefile{lol}{\contentsline {lstlisting}{code/multiple\textunderscore linear\textunderscore regression\textunderscore be.py}{10}}
\newlabel{uloha1:pic1}{{2.4}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Calling summary function in Python. We choose the variable with biggest P-value and remove it.}}{11}}
\@writefile{lol}{\contentsline {lstlisting}{code/multiple\textunderscore linear\textunderscore regression.R}{11}}
\@writefile{lol}{\contentsline {lstlisting}{code/multiple\textunderscore linear\textunderscore regression\textunderscore be.R}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Polynomial Regression}{12}}
\@writefile{lol}{\contentsline {lstlisting}{code/polynomial\textunderscore regression.py}{12}}
\@writefile{lol}{\contentsline {lstlisting}{code/polynomial\textunderscore regression.R}{12}}
\newlabel{uloha1:pic1}{{2.5}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Polynomialregression in Python}}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Support Vector Regression (SVR)}{13}}
\@writefile{lol}{\contentsline {lstlisting}{code/svr.py}{13}}
\newlabel{uloha1:pic1}{{2.6}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Support Vector regression in Python}}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Decision Tree Regression}{14}}
\@writefile{lol}{\contentsline {lstlisting}{code/decision\textunderscore tree\textunderscore regression.py}{14}}
\@writefile{lol}{\contentsline {lstlisting}{code/decision\textunderscore tree\textunderscore regression.R}{14}}
\newlabel{uloha1:pic1}{{2.7}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Decision Tree regression in Python}}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Random Forest Regression}{15}}
\@writefile{lol}{\contentsline {lstlisting}{code/random\textunderscore forest\textunderscore regression.py}{15}}
\@writefile{lol}{\contentsline {lstlisting}{code/random\textunderscore forest\textunderscore regression.R}{16}}
\newlabel{uloha1:pic1}{{2.8}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Random Forest regression in Python}}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Evaluating model performance}{17}}
\@writefile{toc}{\contentsline {subsubsection}{R-squared}{17}}
\@writefile{toc}{\contentsline {subsubsection}{Adjusted R-squared}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Classification}{18}}
\newlabel{uloha1:pic1}{{3}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Visualisation of the dataset for Classification problems. 1 means purchased, 0 means otherwise. Python}}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Classification code template in Python}{19}}
\@writefile{lol}{\contentsline {lstlisting}{code/classification\textunderscore template.py}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Classification code template in R}{20}}
\@writefile{lol}{\contentsline {lstlisting}{code/classification\textunderscore template.R}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Logistic regression}{21}}
\newlabel{uloha1:pic1}{{3.3}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Top - Simple Linear Regression, Bottom - Logistic Regression}}{22}}
\@writefile{lol}{\contentsline {lstlisting}{code/logistic\textunderscore regression.py}{23}}
\@writefile{lol}{\contentsline {lstlisting}{code/logistic\textunderscore regression.R}{23}}
\newlabel{uloha1:pic1}{{3.3}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Logistic regression in Python}}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}K-Nearest neighbours}{24}}
\@writefile{lol}{\contentsline {lstlisting}{code/knn.py}{24}}
\@writefile{lol}{\contentsline {lstlisting}{code/knn.R}{24}}
\newlabel{uloha1:pic1}{{3.4}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces k-NN algorithm with $k=5$ in Python}}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}SVM (Support Vector Machine)}{25}}
\newlabel{uloha1:pic1}{{3.5}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Support Vector Machine basic}}{26}}
\@writefile{lol}{\contentsline {lstlisting}{code/svm.py}{26}}
\@writefile{lol}{\contentsline {lstlisting}{code/svm.R}{26}}
\newlabel{uloha1:pic1}{{3.5}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Support Vector Machine with \textbf  {linear} kernel in Python}}{27}}
\newlabel{uloha1:pic1}{{3.5}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Support Vector Machine with \textbf  {RBF} kernel in Python}}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Kernel SVM}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Naive Bayes}{28}}
\@writefile{lol}{\contentsline {lstlisting}{code/naive\textunderscore bayes.py}{29}}
\@writefile{lol}{\contentsline {lstlisting}{code/naive\textunderscore bayes.R}{29}}
\newlabel{uloha1:pic1}{{3.7}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Naive Bayes Classifier in Python}}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8}Decision Tree Classification}{30}}
\@writefile{lol}{\contentsline {lstlisting}{code/decision\textunderscore tree\textunderscore classification.py}{30}}
\@writefile{lol}{\contentsline {lstlisting}{code/decision\textunderscore tree\textunderscore classification.R}{30}}
\newlabel{uloha1:pic1}{{3.8}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Decision Tree in Python}}{31}}
\newlabel{uloha1:pic1}{{3.8}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Decision Tree in R. Visualisation and Decision Tree itself}}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9}Random Forest Classification}{32}}
\@writefile{lol}{\contentsline {lstlisting}{code/random\textunderscore forest\textunderscore classification.py}{32}}
\@writefile{lol}{\contentsline {lstlisting}{code/random\textunderscore forest\textunderscore classification.R}{32}}
\newlabel{uloha1:pic1}{{3.9}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Random Forest Classifier with 10 Decision Trees in Python}}{33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.10}Evaluating Classification model performance}{33}}
\@writefile{toc}{\contentsline {subsubsection}{Confusion matrix}{33}}
\newlabel{uloha1:pic1}{{3.10}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Confusion matrix}}{34}}
\@writefile{toc}{\contentsline {subsubsection}{Accuracy paradox}{34}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Situation before}}{34}}
\newlabel{my-label}{{1}{34}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Situation without model but with better AR}}{35}}
\newlabel{my-label}{{2}{35}}
\@writefile{toc}{\contentsline {subsubsection}{CAP curve}{35}}
\newlabel{uloha1:pic1}{{3.10}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces CAP curve explained}}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Clustering}{36}}
\newlabel{uloha1:pic1}{{4}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Visualisation of the dataset for clustering problem in Python}}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}K-means clustering}{37}}
\@writefile{toc}{\contentsline {subsubsection}{Elbow method to find optimal K}{37}}
\newlabel{uloha1:pic1}{{4.1}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Elbow method to determine the optimal K in Python}}{38}}
\@writefile{toc}{\contentsline {subsubsection}{Implementation}{38}}
\@writefile{lol}{\contentsline {lstlisting}{code/kmeans.py}{38}}
\@writefile{lol}{\contentsline {lstlisting}{code/kmeans.R}{39}}
\newlabel{uloha1:pic1}{{4.1}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Result of K-mean algorithm in Python, blue points are centroids.}}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Hierarchical clustering}{40}}
\@writefile{toc}{\contentsline {subsubsection}{Dendrograms}{41}}
\newlabel{uloha1:pic1}{{4.2}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Dendrogram - scipy library in Python}}{41}}
\newlabel{uloha1:pic1}{{4.2}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Result of hierarchical clustering in Python}}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Association rule learning}{43}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Apriori}{43}}
\@writefile{lol}{\contentsline {lstlisting}{code/apriori.R}{43}}
\newlabel{uloha1:pic1}{{5.1}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Summary of the R object. It is the matrix with a small amount of "ones" and a lot of "zeros". The number of rows equals the number of transactions and number of columns equals the cardinality of bought items set}}{44}}
\newlabel{uloha1:pic1}{{5.1}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Visualisation of the most bought products. That means it shows their support}}{45}}
\newlabel{uloha1:pic1}{{5.1}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Top 10 found rules in the dataset of bascet. Sorted by lift}}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Eclat}{46}}
\@writefile{lol}{\contentsline {lstlisting}{code/eclat.R}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Reinforcement learning}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Upper Confidence Bound (UCB)}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Thompson sampling}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Natural language processing}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Deep learning}{49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Artificial Neural Network}{49}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Convolutional Neural Network}{49}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Dimensionality reduction}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Principal Component Analysis (PCA)}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Linear Discriminant Analysis (LDA)}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Kernel PCA}{50}}
\bibdata{references}
\citation{*}
\@writefile{toc}{\contentsline {section}{\numberline {10}Model selection and boosting}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Model selection}{51}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}XGBoost}{51}}
